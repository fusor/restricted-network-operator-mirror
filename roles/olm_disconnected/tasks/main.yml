- name: Set exposed_registry
  set_fact:
    exposed_registry: "{{ local_registry }}"

- when: local_registry == "image-registry.openshift-image-registry.svc:5000"
  block:

  - name: Expose OpenShift internal registry
    shell: oc patch configs.imageregistry.operator.openshift.io/cluster -p='{"spec":{"defaultRoute":true}}' --type=merge

  - name: Wait for registry route to be available
    shell: oc get images.config.openshift.io -o yaml | egrep -o 'default-route.*$' | sort -u
    register: registry_route
    retries: 20
    delay: 3
    until: registry_route.rc == 0

  - name: Update exposed_registry
    set_fact:
      exposed_registry: "{{ registry_route.stdout }}"

  - name: Create registry service account
    k8s:
      state: present
      definition: "{{ lookup('file', 'registry.sa.yml') }}"

  - name: Get registry service account token
    shell: oc sa -n openshift-marketplace get-token registry
    register: registry_sa_token

  - block:
    - name: Docker login to internal OpenShift registry
      shell: docker login {{ registry_route.stdout }}  -u registry -p {{ registry_sa_token.stdout }}
    rescue:
    - pause:
        prompt: Add {{ registry_route.stdout }} to your insecure regisries, restart docker, then press return to try again

    - name: Docker login to internal OpenShift registry
      shell: docker login {{ registry_route.stdout }}  -u registry -p {{ registry_sa_token.stdout }}

  - name: Create namespaces for internal registry
    k8s:
      state: present
      definition: "{{ lookup('template', 'namespace.yml.j2') }}"
    with_items:
    - "{{ local_registry_ns }}"

  - name: Add local_registry_ns permissions
    shell: oc policy add-role-to-group system:image-puller system:serviceaccounts:{{ deployment_namespace }} --namespace={{ local_registry_ns }}

- name: Disable default catalog
  shell: "oc patch OperatorHub cluster --type json -p '[{\"op\": \"add\", \"path\": \"/spec/disableAllDefaultSources\", \"value\": true}]'"

- name: Create the deployment namespace
  k8s:
    state: present
    definition: "{{ lookup('template', 'namespace.yml.j2') }}"
  with_items:
  - "{{ deployment_namespace }}"

- name: Make temp directory
  tempfile:
    state: directory
    suffix: mig_olm_disconnected
  register: tmp_dir

- include_tasks: get_operator.yml
  loop: "{{ operators }}"
  loop_control:
    loop_var: operator
  vars:
    tmp_dir_path: "{{ tmp_dir.path }}"

- name: Initialize lists
  set_fact:
    operator_versions: []
    operator_digests: []

- name: Create catalog directory structure
  file:
    path: "{{ tmp_dir.path }}/manifests/{{ item.name }}"
    state: directory
  with_items: "{{ operators }}"

- name: Extract operator metadata
  shell: "bsdtar --strip-components 1 -xf {{ item.name }}.tar.gz -C manifests/{{ item.name }}/"
  args:
    chdir: "{{ tmp_dir.path }}"
  with_items: "{{ operators }}"

- include_tasks: fix_csvs.yml
  loop: "{{ operators }}"
  loop_control:
    loop_var: operator
  vars:
    tmp_dir_path: "{{ tmp_dir.path }}"
  when: operator.type == "dev" or operator.type == "stage"

- name: Copy custom-registry Dockerfile into place
  copy:
    src: Dockerfile
    dest: "{{ tmp_dir.path }}/Dockerfile"

- name: Build custom-registry
  shell: docker build -f Dockerfile -t {{ exposed_registry }}/{{ local_registry_ns }}/custom-registry .
  args:
    chdir: "{{ tmp_dir.path }}"

- name: Push custom-registry
  shell: docker push {{ exposed_registry }}/{{ local_registry_ns }}/custom-registry
  args:
    chdir: "{{ tmp_dir.path }}"

- name: Create custom registry
  k8s:
    state: present
    definition: "{{ lookup('template', 'catalog.yml.j2') }}"

- name: Initialize mirrors
  set_fact:
    mirrors: []

- include_tasks: mirror_images.yml
  loop: "{{ operators }}"
  loop_control:
    loop_var: operator
  vars:
    tmp_dir_path: "{{ tmp_dir.path }}"

- name: Create image content source policies
  k8s:
    state: present
    definition: "{{ lookup('template', 'image-content-source-policy.yml.j2') }}"

- name: Message
  debug:
    msg:
    - "Note an ImageContentSourcePolicy was just created. This will cause nodes to start rebooting and cause some cluster instability while completing. For best results be patient and wait for this process to finish (it can take more than 30 minutes for a 12 node cluster). Until a check is implemented here you can watch progress with:"
    - "watch 'oc describe node -l node-role.kubernetes.io/worker= | grep -e Name: -e rendered'"
